{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541493c4-a174-4297-9033-25fc5d98bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/16 02:02:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/16 02:02:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb46c692-44d7-4645-8044-1720c263ea73",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe50384d-78ea-461c-a8bd-af4171f03633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n",
      "Begin month 04\n",
      "Completed month 04\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_\"\n",
    "YEAR = '2022'\n",
    "MONTHS = range(2, 5)\n",
    "output_relative_dir = '../data/raw/fhvhv_TEST'\n",
    "\n",
    "for month in MONTHS:\n",
    "    month = str(month).zfill(2) \n",
    "    print(f\"Begin month {month}\")\n",
    "    \n",
    "    # generate url\n",
    "    url = f'{URL_TEMPLATE}{YEAR}-{month}.parquet'\n",
    "    # generate output location and filename\n",
    "    output_dir = f\"{output_relative_dir}/{YEAR}-{month}.parquet\"\n",
    "    # download\n",
    "    urlretrieve(url, output_dir) \n",
    "    \n",
    "    print(f\"Completed month {month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc5a7ee-e79f-4697-acf2-e1e292fb53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/20 21:51:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Ass1 ESA\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65d78f7-e0cb-40cc-b16f-38b3156b799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet('../data/raw/fhvhv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5baebc61-66bd-4276-acba-9fe4d9f0629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 22:05:40 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=====================================>                    (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 22:05:42 ERROR Executor: Exception in task 5.0 in stage 4.0 (TID 21)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1473/1793016015.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/08/17 22:05:42 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 5.0 in stage 4.0 (TID 21),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1473/1793016015.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/08/17 22:05:42 ERROR Executor: Exception in task 7.0 in stage 4.0 (TID 23)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1473/1793016015.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/08/17 22:05:42 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 7.0 in stage 4.0 (TID 23),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1473/1793016015.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/08/17 22:05:42 WARN TaskSetManager: Lost task 5.0 in stage 4.0 (TID 21) (fedora executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1473/1793016015.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/08/17 22:05:42 ERROR TaskSetManager: Task 5 in stage 4.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=====================================>                    (9 + 4) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 22:05:43 ERROR Executor: Exception in task 9.0 in stage 4.0 (TID 25)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/08/17 22:05:43 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 9.0 in stage 4.0 (TID 25),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/formatters.py\", line 222, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/formatters.py\", line 707, in __call__\n",
      "    printer.pretty(obj)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/lib/pretty.py\", line 410, in pretty\n",
      "    return _repr_pprint(obj, self, cycle)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/lib/pretty.py\", line 778, in _repr_pprint\n",
      "    output = repr(obj)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/dataframe.py\", line 620, in __repr__\n",
      "    return self._jdf.showString(\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/formatters.py:707\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    701\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    703\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    704\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    705\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    706\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 707\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m callable(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/dataframe.py:620\u001b[0m, in \u001b[0;36mDataFrame.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m     vertical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplEagerEvalMaxNumRows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplEagerEvalTruncate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m sdf \u001b[38;5;241m=\u001b[39m sdf\u001b[38;5;241m.\u001b[39mfilter((F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_per_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_per_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m.5\u001b[39m))\n\u001b[1;32m      7\u001b[0m sdf\u001b[38;5;241m.\u001b[39mfilter(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mairport_fee\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfilter((F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_per_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_per_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m----> 8\u001b[0m sdf\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/displayhook.py:262\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_displayhook()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_output_prompt()\n\u001b[0;32m--> 262\u001b[0m format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_format_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_user_ns(result)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_exec_result(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/displayhook.py:151\u001b[0m, in \u001b[0;36mDisplayHook.compute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_format_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, result):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute format data of the object to be displayed.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    The format data is a generalization of the :func:`repr` of an object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/formatters.py:230\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m ip \u001b[38;5;241m=\u001b[39m get_ipython()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(\u001b[38;5;241m*\u001b[39mexc_info)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2004\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2004\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/ipykernel/zmqshell.py:542\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    536\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    537\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    539\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m'\u001b[39m : stb,\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    543\u001b[0m }\n\u001b[1;32m    545\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from scipy.stats import ttest_ind\n",
    "sdf = sdf.withColumn(\"price_per_dist\", sdf.base_passenger_fare/sdf.trip_time)\n",
    "sdf = sdf.withColumn(\"isAirportTrip\", sdf.airport_fee > 0)\n",
    "sdf = sdf.filter((F.col(\"price_per_dist\") > 0) & (F.col(\"price_per_dist\") < .5))\n",
    "\n",
    "sdf.filter(F.col(\"airport_fee\") > 0).filter((F.col(\"price_per_dist\") > 0)).select(\"price_per_dist\").summary()\n",
    "sdf.limit(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5fea46-1f16-4396-a0d8-f3ce6dd3a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>price_per_dist</th></tr>\n",
       "<tr><td>count</td><td>28881818</td></tr>\n",
       "<tr><td>mean</td><td>0.021942136160303535</td></tr>\n",
       "<tr><td>stddev</td><td>0.009817421488282402</td></tr>\n",
       "<tr><td>min</td><td>2.102165230187093E-6</td></tr>\n",
       "<tr><td>25%</td><td>0.01633776091081594</td></tr>\n",
       "<tr><td>50%</td><td>0.019609800362976406</td></tr>\n",
       "<tr><td>75%</td><td>0.024565217391304347</td></tr>\n",
       "<tr><td>max</td><td>0.4981944444444444</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------------+\n",
       "|summary|      price_per_dist|\n",
       "+-------+--------------------+\n",
       "|  count|            28881818|\n",
       "|   mean|0.021942136160303535|\n",
       "| stddev|0.009817421488282402|\n",
       "|    min|2.102165230187093E-6|\n",
       "|    25%| 0.01633776091081594|\n",
       "|    50%|0.019609800362976406|\n",
       "|    75%|0.024565217391304347|\n",
       "|    max|  0.4981944444444444|\n",
       "+-------+--------------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.filter(F.col(\"airport_fee\") == 0).select(\"price_per_dist\").filter((F.col(\"price_per_dist\") > 0)).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37c868c-9b3a-463c-bb29-47e4520d217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 22:01:57 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================>                    (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 22:01:58 ERROR Executor: Exception in task 5.0 in stage 7.0 (TID 36)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$4050/1968535353.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2840/1898816468.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1474/372871294.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "22/08/17 22:01:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 5.0 in stage 7.0 (TID 36),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$4050/1968535353.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2840/1898816468.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1474/372871294.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "22/08/17 22:01:58 WARN TaskSetManager: Lost task 5.0 in stage 7.0 (TID 36) (fedora executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$4050/1968535353.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2840/1898816468.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1474/372871294.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\n",
      "22/08/17 22:01:59 ERROR Executor: Exception in task 1.0 in stage 7.0 (TID 32)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/08/17 22:01:59 ERROR Executor: Exception in task 3.0 in stage 7.0 (TID 34)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$4050/1968535353.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2840/1898816468.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1474/372871294.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "22/08/17 22:01:59 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 1.0 in stage 7.0 (TID 32),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/08/17 22:01:59 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 3.0 in stage 7.0 (TID 34),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n",
      "\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n",
      "\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1696)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:925)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:972)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:266)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:309)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:212)\n",
      "\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:274)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:116)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:553)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$Lambda$4050/1968535353.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2840/1898816468.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1474/372871294.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "22/08/17 22:01:59 ERROR TaskSetManager: Task 5 in stage 7.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24932/451070996.py\", line 1, in <cell line: 1>\n",
      "    df = sdf.sample(0.001, seed=0).toPandas()\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py\", line 205, in toPandas\n",
      "    pdf = pd.DataFrame.from_records(self.collect(), columns=self.columns)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/dataframe.py\", line 817, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/saurabhjhanjee/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43msdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:205\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    206\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2004\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2004\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/ipykernel/zmqshell.py:542\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    536\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    537\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    539\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m'\u001b[39m : stb,\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    543\u001b[0m }\n\u001b[1;32m    545\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/anaconda3/envs/applied-data-science1/lib/python3.10/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "df = sdf.sample(0.001, seed=0).toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dde1aa8e-91b9-4d89-89b6-a159f7a4549d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=51.713138597949616, pvalue=0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df.loc[df[\"isAirportTrip\"]][\"price_per_dist\"], df.loc[df[\"isAirportTrip\"] == False][\"price_per_dist\"], equal_var=False, alternative=\"greater\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66480ecd-bdab-4d19-9641-fbbf66e38199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num       696994\n",
       "dispatching_base_num    696994\n",
       "originating_base_num    513631\n",
       "request_datetime        696994\n",
       "on_scene_datetime       513693\n",
       "pickup_datetime         696994\n",
       "dropoff_datetime        696994\n",
       "PULocationID            696994\n",
       "DOLocationID            696994\n",
       "trip_miles              696994\n",
       "trip_time               696994\n",
       "base_passenger_fare     696994\n",
       "tolls                   696994\n",
       "bcf                     696994\n",
       "sales_tax               696994\n",
       "congestion_surcharge    696994\n",
       "airport_fee             696994\n",
       "tips                    696994\n",
       "driver_pay              696994\n",
       "shared_request_flag     696994\n",
       "shared_match_flag       696994\n",
       "access_a_ride_flag      696994\n",
       "wav_request_flag        696994\n",
       "wav_match_flag          696994\n",
       "price_per_dist          696994\n",
       "isAirportTrip           696994\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "750fb4a0-c459-4a01-a294-7350dad7166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf8UlEQVR4nO3df5AU95nf8ffDMsKD7POiCCmwYg134dBJRwBnoyhFlcuSc0Zn3RlOZRkc64pKqYr8IedOuoR4SZwIV5nSJpR/XNXZV0Vi57iybAnrxwqff2CdsOM6xbK8ZNHJSCJCloQYiODOWscWIzS7++SP6YHZ3e6Znp1f3T2fVxU1Mz09M99pZp/5zvN9vt82d0dERLJlQbcbICIirafgLiKSQQruIiIZpOAuIpJBCu4iIhm0sNsNALjyyit95cqV3W6GiEiqHDly5O/cfWnYfYkI7itXrmRsbKzbzRARSRUzezXqPqVlREQySMFdRCSDFNxFRDJIwV1EJIMU3EVEMigR1TIiIs0YHS+w99BxTk8UWd6fZ+emNWzZMNDtZnVVrJ67mfWb2UNm9oKZPW9m/9zMrjCzx83sxeBySdX+u8zshJkdN7NN7Wu+iPS60fECux55lsJEEQcKE0V2PfIso+OFbjetq+KmZf4U+K67XwusA54HhoEn3H018ERwGzO7DtgGXA/cAnzJzPpa3XAREYC9h45TLE3N2FYsTbH30PEutSgZ6gZ3M/s14H3AlwHc/W13nwA2A/uD3fYDW4Lrm4EH3P2Cu78MnABuaG2zRUTKTk8UG9reK+L03H8dOAf8DzMbN7P/bmaXA1e7+xmA4PKqYP8B4LWqx58KtomItNzy/nxD23tFnOC+EHgv8OfuvgF4kyAFE8FCts053ZOZ7TCzMTMbO3fuXKzGiojMtnPTGvK5mZnffK6PnZvWdKlFyRAnuJ8CTrn7j4PbD1EO9q+b2TKA4PJs1f4rqh5/DXB69pO6+z53H3L3oaVLQ9e9ERGpa8uGAe67bS0D/XkMGOjPc99ta3u+WqZuKaS7/18ze83M1rj7ceADwHPBv+3ASHD5WPCQg8DXzOxzwHJgNfB0OxovIgLlAJ+2YN7u8s24de7/BrjfzC4Dfgb8K8q9/gNmdidwErgdwN2PmdkBysF/ErjL3afCn1ZEpPdUyjcrVT6V8k2gZQHe3OekwztuaGjIteSviPSKjSOHKYRU8wz053ly+ObYz2NmR9x9KOw+LT8gItJhnSjfVHAXEemwTpRvKriLiHRYJ8o3tXCYiEiHVQZNk1AtIyIiLdTu8k2lZUREMkjBXUQkgxTcRUQySMFdRCSDFNxFRDJIwV1EJIMU3EVEMkjBXUQkgxTcRUQySMFdRCSDFNxFRDJIwV1EJIMU3EVEMkjBXUQkgxTcRUQySMFdRCSDFNxFRDIoVnA3s1fM7FkzO2pmY8G2K8zscTN7MbhcUrX/LjM7YWbHzWxTuxovIiLhGum53+Tu6919KLg9DDzh7quBJ4LbmNl1wDbgeuAW4Etm1hf2hCIi0h7NpGU2A/uD6/uBLVXbH3D3C+7+MnACuKGJ1xERkQbFDe4OfM/MjpjZjmDb1e5+BiC4vCrYPgC8VvXYU8E2ERHpkIUx99vo7qfN7CrgcTN7oca+FrLN5+xU/pLYATA4OBizGSIiEkesnru7nw4uzwKPUk6zvG5mywCCy7PB7qeAFVUPvwY4HfKc+9x9yN2Hli5dOv93ICIic9QN7mZ2uZm9q3Id+CDwU+AgsD3YbTvwWHD9ILDNzBaZ2SpgNfB0qxsuIiLR4qRlrgYeNbPK/l9z9++a2U+AA2Z2J3ASuB3A3Y+Z2QHgOWASuMvdp9rSehERCVU3uLv7z4B1Idv/HvhAxGP2AHuabp2IiMyLZqiKiGSQgruISAYpuIuIZJCCu4hIBim4i4hkkIK7iEgGKbiLiGSQgruISAYpuIuIZJCCu4hIBim4i4hkkIK7iEgGKbiLiGSQgruISAYpuIuIZJCCu4hIBim4i4hkkIK7iEgGxTmHqkjPGB0vsPfQcU5PFFnen2fnpjVs2TDQ7WaJNEzBXRKnWwF2dLzArkeepVgqn8+9MFFk1yPPAijAS+ooLSOJUgmwhYkizqUAOzpeaPtr7z10/GJgryiWpth76HjbX1uk1RTcJVG6GWBPTxQb2i6SZArukijdDLDL+/MNbRdJstjB3cz6zGzczP4quH2FmT1uZi8Gl0uq9t1lZifM7LiZbWpHwyWbuhlgd25aQz7XN2NbPtfHzk1r2v7aIq3WSM/9j4Hnq24PA0+4+2rgieA2ZnYdsA24HrgF+JKZ9SESQzcD7JYNA9x321oG+vMYMNCf577b1mowVVIpVrWMmV0D3ArsAf4k2LwZeH9wfT/wA+CTwfYH3P0C8LKZnQBuAH7UslZLZlUCabfKEbdsGFAwl0yIWwr5BeDfA++q2na1u58BcPczZnZVsH0AeKpqv1PBthnMbAewA2BwcLCxVkumKcCKNK9uWsbMfg846+5HYj6nhWzzORvc97n7kLsPLV26NOZTi4hIHHF67huBD5vZh4B3AL9mZl8FXjezZUGvfRlwNtj/FLCi6vHXAKdb2WgREamtbs/d3Xe5+zXuvpLyQOlhd78DOAhsD3bbDjwWXD8IbDOzRWa2ClgNPN3ylouISKRmlh8YAQ6Y2Z3ASeB2AHc/ZmYHgOeASeAud5+KfhoREWk1c5+TDu+4oaEhHxsb63YzRERSxcyOuPtQ2H1aOEykh2kVzOxScBf9gfcorYKZbVpbpsd1cxVG6S6tgpltCu49Tn/gvUurYGab0jI9Lg1/4Eobtcfy/jyFkP9nrYKZDeq597ikL3OrtFH7aBXMbFNw73FJ/wNX2qh9tApmtikt0+O6vQpjPWlIG6WZFmnLLgV3SfQfuPLCIvOjtIwkWtLTRiJJpZ67JFrS00YiSaXgLomX5LSRSFIpuIskiGr6pVUU3EUSQmu9SCspuCeEemxSq6ZfnwVplIJ7AqjHJqCafmktlUImwHxnYY6OF9g4cphVw99i48hhTclPuaQvBSHpouCeAPPpsWnNlexRTb+0koJ7Asynx6Y1V7JHa71IKynnngA7N62ZkXOH+j22rOZnOzWwnNQB7FbU9Cf1vUlnKbgnwHxmYWZxzZVODSxneQA7y+9NGqPgnhCN9tjm09tPuk6VAma55DDL700aUze4m9k7gB8Ci4L9H3L3e83sCuBBYCXwCvBRd38jeMwu4E5gCvgjdz/Ultb3sFq9/bT+LO9UqimrKS3I9nuTxsTpuV8Abnb3X5lZDvgbM/sOcBvwhLuPmNkwMAx80syuA7YB1wPLgb82s99096moF5D5Cevtp/lneadSTVlMaVVk+b1JY+pWy3jZr4KbueCfA5uB/cH2/cCW4Ppm4AF3v+DuLwMngBta2WiJ1mwVTTdr5ztVCpjlksMsvzdpTKycu5n1AUeAfwR80d1/bGZXu/sZAHc/Y2ZXBbsPAE9VPfxUsG32c+4AdgAMDg7O/x3IDM38LO9Wr786jfTufI535BYwcb7UtpRSlpcRzvJ7k8bECu5BSmW9mfUDj5rZb9fY3cKeIuQ59wH7AIaGhubcL/PTzM/ybgzGzf5CmSiWyOf6+PzW9W0NSFleRjjL703ia2gSk7tPAD8AbgFeN7NlAMHl2WC3U8CKqoddA5xutqESTzM/y7sxGKfJWCLtUTe4m9nSoMeOmeWBfwG8ABwEtge7bQceC64fBLaZ2SIzWwWsBp5ucbslQjOzHLuxtkmnvlC0Do/0mjhpmWXA/iDvvgA44O5/ZWY/Ag6Y2Z3ASeB2AHc/ZmYHgOeASeAuVcp01nx/lnejdr4T1R1priASma+6wd3d/xbYELL974EPRDxmD7Cn6dZJR3VjMK4VXyj16vo1sUd6kWaoygydHoxr9gslTq9cE3ukFym4S9c184USp1euiT3Si7Tkr6RanF65JvZIL1Jwl1SLU+GjddKlF6U+LZPWRbI6pdHjk7bjGTYgC3D+7UlGxwsX2z7f1E/ajodIRaqDu0rcamv0+KTxeFbatfvgMSaKpYvb3zhfarrtaTweIhWpTstodmNtjR6ftB7PLRsGsJBFL5pte1qPhwikvOeehRK3dv7sjzoOhYkiG0cOz3nNtB7P0fECb5wvhd53eqI472Oc1uMhAikP7nFK3JKcM233z/6o42PBa81+zbSWDNbqSfcvzs37GKf1eIhAytMy9UrcKsGzMFHEufSHnZR1RaJ+9t/94NGL6580syZK2PEx5i7RWUk1dLJksJVrvdTqSbsz79SKSiglzVLdc683uzHp085rBaXCRJGd33gGDEpTfnFbIz37sOMT1hOttKVTyw+E/WLZ+dAz7D54jF8UZ67jHueXV9T76s/n+EUxOl1Tj9ZGlzQz9+4vpT40NORjY2Mtf95Vw9+au5A85d7ryyO3tvz1GrVx5HBksK1loD/Pk8M3t/Q1G33OZtJdcd/35Zf18fbkNKXpS/+L+VzfnBr12V8W1fvtPXS8Je9XJInM7Ii7D4Xdl+q0TD3dWMK2EWE/++NoZkCvFamGZtNdcdv/5ttTMwI7hKdUak1SUmpFelWq0zL1dGMJ20ZU/+xvpAffzJdTK1INzaa7aqWH4gj7coiapKTUivSqTAf3NPxhV4JSWGoht8Bm5NyhNV9OjczWDEu/NFsieNO1S/nqUydjt3e2Rr/cdNo56UWZDu6QvD/sqFx11BdR2LZOvZ+oUs1353MzZoNWxA2633/h3LzblKRfXiJJlukB1aSpNfCXpC+giqiBzyWLc7xVmp7X+xgdL3D3g0djtyHXZ1x+2UJ+USzRvziHO3MqakR6Vc8OqLbLfGu0o3LVuw8ea0czmxaVZpk4X5rXKouVL7coA/15vrB1/Yzn3fuRdRy994N8fut63ipNM1EsJXLOgkjSZD4t0wrVqZT+xTl+9dbkxSqORmrPI4NlsTRjBcOkqDVDcz7prrAvtwqjnIuPet6kz1kQSRr13OuYXfb3xvlSrPK8MLVy0tWzUqtfO+4vhFbO+KyYbxlhVFtqziQFHj5SmNPuynPVmnwlInOp515Hrd5mtXpBZnS8wJsXJmvuU/0rAIi9Jkqr1qgJG+ytTASqN6BbeWxhojhjiYM4a9dUVPfER8cLfPqbxyIXBKtIypwFkaRRcK8jbs8wKsjEDVIV1b8C4qYhWpGyiPqCuO+2tXVncs5+bNjaNXEHUSurOIadgGM2Vc6IRKsb3M1sBfCXwD8EpoF97v6nZnYF8CCwEngF+Ki7vxE8ZhdwJzAF/JG7H2pL6zsgzoSbqCATN0jNVusLpXoJ28JEkT4zpiIqnhpJWTTzBRH3100cy/vzsZ5vQNUyIjXFyblPAv/W3X8LuBG4y8yuA4aBJ9x9NfBEcJvgvm3A9cAtwJfMrPE59gkRlnfO9Rn9+VzdSpH5Br3l/fnIXwJOOT9f+cKJCuwAC8xi596byWk3M9u0WuVLst5rVtaFUWAXiVa35+7uZ4AzwfVfmtnzwACwGXh/sNt+4AfAJ4PtD7j7BeBlMzsB3AD8qNWN74RmZrnWC1L9+RwXJmfWi+f6jDcvTDJRLIUuz9uIKfdYufdaXwBxctq1fj3EfWx1T7zWcgxKxYjE09AkJjNbCfwQ+G3gpLv3V933hrsvMbM/A55y968G278MfMfdH5r1XDuAHQCDg4P/5NVXX23yrYTr9Mk6ql9vQY2gl+sz9n5kHUBkmSWEr7/eqCWLcyy+bGHkMVj/6e+FzjgF+MLW9aEDuHGWEa6lz4yX7vtQ6P8PEJrO6s/n2P3h69VjFwnUmsQUO7ib2TuB/wnscfdHzGwiIrh/EfjRrOD+bXd/OOq52zVDtdMzQhvJsffncxy994Mzts13CeBGzT4GK4e/VXN/s/JJLwb689x07VIePlJoOsd+x42DDL3nisj/H0j2mkAiSVAruMeqljGzHPAwcL+7PxJsft3Mlrn7GTNbBpwNtp8CVlQ9/Brg9Pya3pxaM0LbETgaybFXTiJR3XPt1EIQjVbSVL7/CxNF7n/qZOx2LjCYDtn58sv6+MyWtWwcORw5iKucukhz4lTLGPBl4Hl3/1zVXQeB7cBIcPlY1favmdnngOXAauDpVja6ljjBcqJYupiGKEwUuefBo9z94NGmKzAaqU55dz4372qaVqi0dXS8EBmEwzTyBTTt5Z747J75nj9YO6MNUW0TkfmLUy2zEfhD4GYzOxr8+xDloP47ZvYi8DvBbdz9GHAAeA74LnCXu3ckeo2OF9j5jWcuziaNa/aEm/nO7mxkQs2bb0+y++CxrgR2mPnlEjewN6pSSRS1Bk3ST6YikmZxqmX+hvK4XpgPRDxmD7CniXbFVt1Th+YHHysTbj79zWOxViCsfv1353OxX6c05ZGDmJ0wUSw1tDpjo3ILrG5VS9JPpiKSZqle8rfRtMZAf57zb0/Gni1arXrp2eqqjp0PPTPjZBqtUEkP3fPg0Y7l4Vst12ds/acr5gy+zh7M7XQ1k0iWtKRapp3mG9wbqS6prsJoRZ47n+tjgZXP89lKlXaOvfrzps5W1C753ALAYh2/qPp3nZxapDUyu557IwNv1RUi9922lj6LyjTFf75WB/ZKTvobYye7HthzfVY+zV8VA4qlaRYtXMCSxZdm6EZpxbIIIjI/qQ7ujQ68VYLKlg0DTCfgF8tshYki//HRZ3nypZ93uymUppzpYOYozJxMNVEs8VZpms9vXc+TwzdHBvioL1ANmIq0X6qD+03XLo0c6Q1THVS6EWAG+vM1e7rQ+jRPM6Yczv3yLSB8pcdPf7N8Bqmodd8/9s9WzGs9eBFpXmqD++h4gYePFGIPOM4OKmEBqZ0qZxqqt6Z70rxdY7D4jfOXziAVVvL4mS1r53U6PhFpXmoHVBsZTI1ak6Qbs0OzRoOjIt3T9PIDSRRnUK7ejNPqFR87saZLFmlwVCSZUpuWiZMzPz1RZO+h45EzTqvPjyrzo8FRkWRKbXCPkzN3opcUGB0vcM+Bo12b/p8G9Qar48xCFZHuSG1wrwziLVlcf8p/9XlJIViD5qFnSMBwQ9dt/I0ruOPGwYtli31m3HHjIK+M3Mrnt66nv9aSCs1NFRCRNkptzh3KAX7LhoFYA6PVueG9h463fMmAtHrypZ+zauk7eem+D4Xef2FyOvKxpSlvaOngLNLyCZJUqe25V9uyYYAnh2/m5ZFbI+vIq3PDGgSc6es/fi10e5z16Xv5WFaP2dRKAYp0Q6p77mG9pjgrDfYvzs1r8bCsmnIPPZZxAncvD6hGnQym13/NSDKktuce1WsCak6c+dToswrssxiEHsv+OuMZvT7bVCcbkSRLbc+9Vq8p6hRtnxp9tusLciWRQ+ixXLRwwZwzKVXWmGn2rFVZEHVy8F7+NSPJkdrg3mivaXS8wP0K7A35RbHE57eu14BhBJ1sRJIstcE9Km/evzgXmj/ee+i4lhho0PL+/MWKJJmreoazvvwkaVK7tsxv/afvUCzNLdPLLYCFfXNPyqzJSo2ZfcYkEUmeTK4tExbYAUrTUJqemz+WeAzUAxXJgNQGd2k9rfAokh2pLYVcoKnvLaWBQJFsqRvczewrZnbWzH5ate0KM3vczF4MLpdU3bfLzE6Y2XEz29Suhk93f6gg9frMdBINkYyKk5b5C+DPgL+s2jYMPOHuI2Y2HNz+pJldB2wDrgeWA39tZr/p7i1Peg9E1BjLJX1mfPaj6wBCS/YU0EWyq27P3d1/CMw+Y/NmYH9wfT+wpWr7A+5+wd1fBk4AN7SmqTMphVDfZz+67mIpo053J9Jb5jugerW7nwFw9zNmdlWwfQB4qmq/U8G2OcxsB7ADYHBwcJ7NkCj9+dyM4K16dZHe0upqmbBhztDsuLvvA/ZBuc690RfaffBYow/pGQbs/vD1jI4X+PQ3j12c7BV1LlkRyZ75Vsu8bmbLAILLs8H2U8CKqv2uAU7Pv3nRJopa/CvKx28s/xLa+dAzM2bxThRL7PzGM1qSVqQHzDe4HwS2B9e3A49Vbd9mZovMbBWwGni6uSZKXP35HF/Yup7PbFkbeUKS0rTPOCuViGRT3bSMmX0deD9wpZmdAu4FRoADZnYncBK4HcDdj5nZAeA5YBK4qx2VMuV2odPkBXILjL23r5uRbqm17KyWpBXJvrrB3d0/FnHXByL23wPsaaZRcSiwX1LpjVcH96jlaCv3iUi2pXaGas0TN2fU6qsuj7xvdm9856Y15Prmjm/nFpjKSEV6QGrXlrEeW34gn1vAqTfeirx/dm+80otXtYxIb0ptcO+1U+W9NTkdmYoKWxdGZZAivS21wb3X1BpjmD3bdHS8wM6HnplRLTNRLPEnB46y++AxflEsaVlfkYxTcE+5geBsSdWiyiCn/dL8gOoTilceo7MJiWSHgnuKGeUgvXHk8IyAHLfUsViaYvfBY1yYnL64qFh10FeAF0mv1FbL9KrKQLJxaV2HwkSRex48yqdGy0G5kVLHiWJpzpmqiqUpTXQSSTkF9wRYtLDx/4bZSRcH7n/qZDnfHlEG2QhNdBJJNwX3BLgwOc3ll/XF2rfWwKrDxclMez+yjiWLL80FWJxbQG7W6avyub4Z+1TTRCeRdFPOPSHefLs1qzRUetxhS/yOjhfmDJxC+Ik8NNFJJN0U3DOmVo+71pruqpYRyRYF9wyZb49bJ/IQyR7l3LtgoD8fmeuuZfYQaW6BsWRxTqfOE5E5FNw7aMniHK+M3MqTwzdz7+9fTz4XbxAVyr3yj984OOM8qFtvWMHiy/TjS0TmUmTokHyuj3t///qLtys97Opc98p/kOd/vfTzOWWOYevCjI4XZgyEavKRiFRTcG+T3ALjne9YyBvnS/SZzZgYVAm+s3PdG0cOh55w9vJFC0OXGIiafKTgLiJKy7TJ3tvXces/XoYBU0FxeqV3HXUO06iJQ2HbG9lXRHqPgnub3P3gUb761Mk5PfFaU/ujyhjDtjeyr4j0HgX3LojqXe/ctGbOIGtUeWMj+4pI71HOvQuietdhg6xRE4rC9r3p2qXsPXScex48qslIIj1Owb3DDGr2rhuZUFS9r6pnRKSa0jIdZMDHbxxsS7CtVT0jIr2nbcHdzG4xs+NmdsLMhtv1Omny8RsH+cyWtW15blXPiEi1tgR3M+sDvgj8LnAd8DEzu64dr5UmDx8pRJZBNkvVMyJSrV099xuAE+7+M3d/G3gA2Nym10qNdqZJVD0jItXaFdwHgNeqbp8Ktl1kZjvMbMzMxs6dO9emZiRPu9IkWzYMcN9ta2esPaOFxER6V7uqZcLO8TZjPo+77wP2AQwNDdU4v1C2tDNNoqV7RaSiXT33U8CKqtvXAKfb9FqJUTmL3UB/njtuHJyTJjHgpmuXdr5hItJz2tVz/wmw2sxWAQVgG/Av2/RaibFoYd+cVMj9VUsQOOVB1aH3XKEetoi0VVt67u4+CXwCOAQ8Dxxw92PteK0kmT1g+v0XzjW0toyISKu0bYaqu38b+Ha7nn+gP08hgTXchYkiG0cOc3qiGLp8L6j2XETaL7UzVMNK/yqnneu2Qo3ADqo9F5H2S21wDyv923v7Osb/8wf5wtb1DZ3CrpNUey4inZDqhcOiSv8q2+45cBRvUZHlQLDq4iNHTnG+NN3w4w20UqOIdEyqg3stlQC68xvPUJpuLsIvWZzjyeGbgfIg6fkGc+YD/fmLjxcR6YTUpmXi2LJhgL23r5uRurnjxsHI21EmzpcuXm90MFRpGBHphsz23CsambW5ceRwaAVO9QDo8jpVOpUTY0+cLykNIyJdk/ng3oidm9bMOOEFzO15h+1jlCcoDSiYi0hCKLhXiXOau0ZOhSci0i3mrSonacLQ0JCPjY11uxkiIqliZkfcfSjsvkwPqIqI9CoFdxGRDFJwFxHJIAV3EZEMUnAXEcmgRFTLmNk54NUmnuJK4O9a1Jw003Eo03Eo03Eoy/JxeI+7h57eLRHBvVlmNhZVDtRLdBzKdBzKdBzKevU4KC0jIpJBCu4iIhmUleC+r9sNSAgdhzIdhzIdh7KePA6ZyLmLiMhMWem5i4hIFQV3EZEMSnVwN7NbzOy4mZ0ws+Fut6eTzOwVM3vWzI6a2Viw7Qoze9zMXgwul3S7na1mZl8xs7Nm9tOqbZHv28x2BZ+P42a2qTutbr2I47DbzArBZ+KomX2o6r6sHocVZvZ9M3vezI6Z2R8H23vuMzGHu6fyH9AHvAT8OnAZ8AxwXbfb1cH3/wpw5axt/xUYDq4PA/+l2+1sw/t+H/Be4Kf13jdwXfC5WASsCj4vfd1+D208DruBfxeyb5aPwzLgvcH1dwH/J3i/PfeZmP0vzT33G4AT7v4zd38beADY3OU2ddtmYH9wfT+wpXtNaQ93/yHw81mbo973ZuABd7/g7i8DJyh/blIv4jhEyfJxOOPu/zu4/kvgeWCAHvxMzJbm4D4AvFZ1+1SwrVc48D0zO2JmO4JtV7v7GSh/6IGruta6zop63734GfmEmf1tkLappCJ64jiY2UpgA/Bj9JlIdXC3kG29VNe50d3fC/wucJeZva/bDUqgXvuM/DnwG8B64Azw2WB75o+Dmb0TeBi4293/X61dQ7Zl6lhUpDm4nwJWVN2+BjjdpbZ0nLufDi7PAo9S/mn5upktAwguz3avhR0V9b576jPi7q+7+5S7TwP/jUvphkwfBzPLUQ7s97v7I8Hmnv9MpDm4/wRYbWarzOwyYBtwsMtt6ggzu9zM3lW5DnwQ+Cnl97892G078Fh3WthxUe/7ILDNzBaZ2SpgNfB0F9rXEZVgFvgDyp8JyPBxMDMDvgw87+6fq7qr5z8TC7vdgPly90kz+wRwiHLlzFfc/ViXm9UpVwOPlj/XLAS+5u7fNbOfAAfM7E7gJHB7F9vYFmb2deD9wJVmdgq4Fxgh5H27+zEzOwA8B0wCd7n7VFca3mIRx+H9ZraecprhFeBfQ7aPA7AR+EPgWTM7Gmz7D/TgZ2I2LT8gIpJBaU7LiIhIBAV3EZEMUnAXEckgBXcRkQxScBcRySAFdxGRDFJwFxHJoP8Pq33sPWYjSCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(df[\"trip_miles\"], df[\"base_passenger_fare\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f916db93-cc6a-4479-83c2-1b940e9b2301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.40000e+02, 1.15382e+05, 2.76000e+03, 2.05000e+02, 3.50000e+01,\n",
       "        1.00000e+01, 3.00000e+00, 1.00000e+00, 0.00000e+00, 2.00000e+00]),\n",
       " array([-0.02114754,  0.0075293 ,  0.03620615,  0.064883  ,  0.09355984,\n",
       "         0.12223669,  0.15091353,  0.17959038,  0.20826722,  0.23694407,\n",
       "         0.26562092]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[abs(df[\"price_per_dist\"]) < 0.3][\"price_per_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a15c9bc-8543-4384-b28f-137fbde55dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f3fde08fbb0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18cfd0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18cd00>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18d690>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f3fda18c2e0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18c280>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18d960>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18dc30>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f3fde08f8e0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18d0f0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f3fda18c8b0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18df00>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f3fda18c850>,\n",
       "  <matplotlib.lines.Line2D at 0x7f3fda18e1d0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot((df.loc[df[\"isAirportTrip\"]][\"price_per_dist\"], df.loc[df[\"isAirportTrip\"] == False][\"price_per_dist\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f20d75c2-4ad2-4cd8-b6a8-7d6f401e3713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "      <th>price_per_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>HV0004</td>\n",
       "      <td>2021-01-20 08:21:13</td>\n",
       "      <td>2021-01-20 08:23:45</td>\n",
       "      <td>2021-01-20 08:23:49</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>8.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52348</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-01-15 14:10:35</td>\n",
       "      <td>2021-01-15 14:16:14</td>\n",
       "      <td>2021-01-15 14:16:20</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.43</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.061667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>2021-01-01 00:10:24</td>\n",
       "      <td>2021-01-01 00:12:04</td>\n",
       "      <td>2021-01-01 00:12:17</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>0.017</td>\n",
       "      <td>13</td>\n",
       "      <td>10.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.834615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43098</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-01-13 02:50:47</td>\n",
       "      <td>2021-01-13 02:51:16</td>\n",
       "      <td>2021-01-13 02:51:29</td>\n",
       "      <td>197</td>\n",
       "      <td>134</td>\n",
       "      <td>0.030</td>\n",
       "      <td>13</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.39</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90588</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-01-25 06:10:29</td>\n",
       "      <td>2021-01-25 06:18:02</td>\n",
       "      <td>2021-01-25 06:26:21</td>\n",
       "      <td>247</td>\n",
       "      <td>69</td>\n",
       "      <td>1.210</td>\n",
       "      <td>499</td>\n",
       "      <td>159.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.320621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50394</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-01-15 00:49:33</td>\n",
       "      <td>2021-01-15 00:56:02</td>\n",
       "      <td>2021-01-15 01:06:14</td>\n",
       "      <td>160</td>\n",
       "      <td>197</td>\n",
       "      <td>2.520</td>\n",
       "      <td>612</td>\n",
       "      <td>162.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.265621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67464</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>2021-01-19 13:37:51</td>\n",
       "      <td>2021-01-19 13:39:27</td>\n",
       "      <td>2021-01-19 13:39:56</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>0.127</td>\n",
       "      <td>29</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.251724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95473</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-01-26 13:42:56</td>\n",
       "      <td>2021-01-26 13:46:24</td>\n",
       "      <td>2021-01-26 13:52:13</td>\n",
       "      <td>89</td>\n",
       "      <td>188</td>\n",
       "      <td>0.680</td>\n",
       "      <td>349</td>\n",
       "      <td>70.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.202579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hvfhs_license_num    request_datetime     pickup_datetime  \\\n",
       "69998            HV0004 2021-01-20 08:21:13 2021-01-20 08:23:45   \n",
       "52348            HV0003 2021-01-15 14:10:35 2021-01-15 14:16:14   \n",
       "293              HV0005 2021-01-01 00:10:24 2021-01-01 00:12:04   \n",
       "43098            HV0003 2021-01-13 02:50:47 2021-01-13 02:51:16   \n",
       "90588            HV0003 2021-01-25 06:10:29 2021-01-25 06:18:02   \n",
       "50394            HV0003 2021-01-15 00:49:33 2021-01-15 00:56:02   \n",
       "67464            HV0005 2021-01-19 13:37:51 2021-01-19 13:39:27   \n",
       "95473            HV0003 2021-01-26 13:42:56 2021-01-26 13:46:24   \n",
       "\n",
       "         dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "69998 2021-01-20 08:23:49            48           107       0.000          3   \n",
       "52348 2021-01-15 14:16:20            17            17       0.010          6   \n",
       "293   2021-01-01 00:12:17           262           262       0.017         13   \n",
       "43098 2021-01-13 02:51:29           197           134       0.030         13   \n",
       "90588 2021-01-25 06:26:21           247            69       1.210        499   \n",
       "50394 2021-01-15 01:06:14           160           197       2.520        612   \n",
       "67464 2021-01-19 13:39:56           263           263       0.127         29   \n",
       "95473 2021-01-26 13:52:13            89           188       0.680        349   \n",
       "\n",
       "       base_passenger_fare  tolls  ...  sales_tax  congestion_surcharge  \\\n",
       "69998                25.71    0.0  ...       1.83                  2.75   \n",
       "52348                 6.37    0.0  ...       0.57                  0.00   \n",
       "293                  10.85    0.0  ...       0.96                  2.75   \n",
       "43098                 5.75    0.0  ...       0.51                  0.00   \n",
       "90588               159.99    0.0  ...       0.89                  0.00   \n",
       "50394               162.56    0.0  ...       1.11                  0.00   \n",
       "67464                 7.30    0.0  ...       0.65                  2.75   \n",
       "95473                70.70    0.0  ...       0.51                  0.00   \n",
       "\n",
       "       airport_fee  tips  driver_pay  shared_request_flag shared_match_flag  \\\n",
       "69998          NaN   0.0        0.00                    N                 N   \n",
       "52348          NaN   0.0        5.43                    N                 N   \n",
       "293            NaN   0.0        5.47                    N                 N   \n",
       "43098          NaN   0.0        5.39                    N                 N   \n",
       "90588          NaN   0.0        6.07                    N                 N   \n",
       "50394          NaN   0.0        7.90                    N                 N   \n",
       "67464          NaN   0.0        5.47                    N                 N   \n",
       "95473          NaN   0.0        5.40                    N                 N   \n",
       "\n",
       "      wav_request_flag wav_match_flag price_per_dist  \n",
       "69998                N              N       8.570000  \n",
       "52348                N              N       1.061667  \n",
       "293                  N              N       0.834615  \n",
       "43098                N              N       0.442308  \n",
       "90588                N              N       0.320621  \n",
       "50394                N              N       0.265621  \n",
       "67464                N              N       0.251724  \n",
       "95473                N              N       0.202579  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[abs(df[\"price_per_dist\"]) > 0.2].loc[:, ~df.columns.isin(['originating_base_num', 'dispatching_base_num', 'on_scene_datetime', 'access_a_ride_flag', ...])].sort_values(by=\"price_per_dist\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
